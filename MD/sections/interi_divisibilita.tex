\chapter{Parte 3}
\section{Strutture algebriche elementari}
Una \textbf{operazione binaria intera} su un insieme G è un'applicazione 
\begin{center}
    $\ast \; : \; G \times G \rightarrow G$
\end{center}
L'immagine della coppia $(x,y)$ si denoterà con $x \ast y$. 
\begin{itemize}[nosep]
    \item $e \in G$ si dice \textbf{elemento neutro} rispetto a $\ast$ se:
    \begin{center}
        $g \ast e = e \ast g = g \; \forall g \in G$
    \end{center}
    \item un elemento $g \in G$ si dice invertibile se esiste $\bar{g} \in G$ tale che $g * \bar{g} = \bar{g} * g = e$
\end{itemize}

\subsection{Gruppi}
La coppia $(G, \ast)$, con $\ast$ operazione su G, si dice \textbf{gruppo} se vengono rispettate le seguenti proprietà:
\begin{itemize}[nosep]
    \item $\ast$ è \textbf{associativa}: $\forall g, g', g'' \in G$ si ha $(g \ast g') \ast g'' = g \ast (g' \ast g'')$
    \item esiste l'elemento \textbf{neutro}
    \item ogni elemento di G è invertibile
\end{itemize}
Il gruppo si dice \textbf{abeliano} o \textbf{commutativo} se: 
\begin{center}
    $\forall g, g' \in G, \; g \ast g' = g' \ast g$ (proprietà \textbf{commutativa})
\end{center}
Alcuni \textcolor{orange}{\textbf{esempi}}:
\begin{itemize}[nosep]
    \item $(\mathbb{N}, +)$, $(\mathbb{Z}, \cdot)$ non sono gruppi. In quanto non né in $\mathbb{N}$ né in $\mathbb{Z}$ è presente per ogni elemento dell'insieme l'elemento inverso, in $\mathbb{N}$ non sono presenti elementi negativi, quindi nessun elemento avrà un'altro elemento che sommato a se stesso dia 0, viceversa l'insieme $\mathbb{Z}$ dove sono presenti elementi positivi e negativi viene, invece, definita l'operazione $\cdot$ che richiede i reciproci dei singoli elementi affiché possano essere definiti gli elementi inversi.
    \item $(\mathbb{Z}, +)$, $(\mathbb{Q}, \cdot)$ sono gruppi abelliani
\end{itemize}

\subsection{Anelli}
La terna $(\mathbb{A}, +, \cdot)$ con $\mathbb{A}$ un insieme e $+, \cdot$ (somma e prodotto) due operazione binarie interne a $\mathbb{A}$, si dice \textbf{anello} se:
\begin{itemize}[nosep]
    \item $(\mathbb{A}, +, \cdot)$ è un gruppo \textbf{abeliano} (con elemento neutro 0).
    \item il prodotto è \textbf{associativo}.
    \item per ogni $x,y,z \in \mathbb{K}$ si ha $x \cdot (y + z) = (x \cdot y) + (x \cdot z)$ e $(x + y) \cdot z = (x \cdot z) + (y \cdot z)$ (il prodotto è distribuito rispetto alla somma).
\end{itemize}
Un anello $(\mathbb{A}, +, \cdot)$ è detto \textbf{commutativa} se il prodotto è commutativo, mentre è detto \textbf{unitario} o con \textbf{unità} se $(\mathbb{A}, \cdot)$ ammette l'elemento neutro. $(\mathbb{Z}, +, \cdot)$, $(\mathbb{Q}, +, \cdot)$, $(\mathbb{R}, +, \cdot)$, $(\mathbb{C}, +, \cdot)$ sono anelli.

\subsection{Campi}
La terna $(\mathbb{K}, +, \cdot)$ con $\mathbb{K}$ un insieme e $+, \cdot$ (somma e prodotto) due operazioni binarie interne a $\mathbb{K}$, si dice \textbf{campo} se:
\begin{itemize}[nosep]
    \item $(\mathbb{K}, +)$ è un gruppo \textbf{abeliano} (con elemento neutro 0).
    \item $(\mathbb{K} - \{0\}, \cdot)$ è un gruppo \textbf{abeliano} (con elemento neutro 1).
    \item per ogni $x,y,z \in \mathbb{K}$ si ha $x \cdot (y + z) = (x \cdot y) + (x \cdot z)$ quindi il prodotto è distribuito rispetto alla somma.
\end{itemize}
In qualunque campo vale la \textbf{legge di annullamento del prodotto}:
\begin{center}
    $x \cdot y = 0 \rightarrow x = 0 \; \text{oppure} \; y = 0$
\end{center}

\subsection{Domini d'integrità}
\textbf{Divisori dello zero}: sia $(A, +, \cdot)$ un anello. Due elementi $a,b \in A$ si dicono \textbf{divisori dello zero} se $a \neq 0$, $b \neq 0$, ma $a \cdot b = 0$. Ovvero, può succedere che in un anello due elementi non nulli il cui prodotto fa 0.
\begin{boxA}
    Ad \textcolor{orange}{\textbf{esempio}} l'anello delle matrici quadrate presenta dei divisori dello zero, infatti due matrici non nulle è possibile che il loro prodotto presenti la matrice nulla.
    \begin{center}
        \begin{math}
            A = \begin{pmatrix}
                1 & 1 \\
                1 & 1
                \end{pmatrix}, \quad B = \begin{pmatrix}
                1 & -1 \\
                -1 & 1
                \end{pmatrix}
        \end{math}
        \begin{math}
            A \cdot B = \begin{pmatrix}
                1 & 1 \\
                1 & 1
                \end{pmatrix} \cdot \begin{pmatrix}
                1 & -1 \\
                -1 & 1
                \end{pmatrix} = \begin{pmatrix}
                (1 \cdot 1 + 1 \cdot -1) & (1 \cdot -1 + 1 \cdot 1) \\
                (1 \cdot 1 + 1 \cdot -1) & (1 \cdot -1 + 1 \cdot 1)
                \end{pmatrix} = \begin{pmatrix}
                0 & 0 \\
                0 & 0
                \end{pmatrix}
        \end{math}
    \end{center}    
\end{boxA}
\textbf{Dominio di Integrità}: Un anello commutativo privo di divisori dello zero si dice \textbf{dominio di integrità}.

\begin{boxA}
    Ad \textcolor{orange}{\textbf{esempio}} $(\mathbb{Z}, +, \cdot)$ è un \textbf{anello commutativo unitario} privo di divisori dello zero. Quindi è dominio di integrità.
\end{boxA}

\section{L'anello dei numeri interi}
È noto che $\exists h \; | \; h : \mathbb{Z} \rightarrow \frac{\mathbb{N}_0 \times \mathbb{N}_0}{\mathcal{R}}$ dove la relazione di equivalenza che si vuole definire è $\equiv_n$. Su questo insieme vengono \textbf{ben poste} le seguenti operazioni:
\begin{center}
    $\boxplus : \mathbb{Z} \times \mathbb{Z} \rightarrow \mathbb{Z}$ \\
    $((m, n), (m', n')) \mapsto [(m, n)] \boxplus [(m', n')] \myeq [(m + m', n + n')]$

    $\boxdot : \mathbb{Z} \times \mathbb{Z} \rightarrow \mathbb{Z}$ \\
    $((m, n), (m', n')) \mapsto [(m, n)] \boxdot [(m', n')] \myeq [(mm' + nn', mn' + m'n)]$
\end{center}
Definito questo possiamo dire che $(\mathbb{Z}, \boxplus, \boxdot)$ è \textbf{dominio di integrità}.

\section{Teoria della Divisibilità}
\textbf{Divisibilità}: dati due numeri $a,b \in \mathbb{Z}$, si dice che $a$ \textbf{divide} $b$ (e si scrive $a|b$) se: $\exists c \in \mathbb{Z} \; | \; b = a \cdot c$
\begin{boxA}
    \textcolor{orange}{\textbf{Esempi}}
    \begin{itemize}[nosep]
        \item $2|12, \; \exists c \; t.c. \; 2 \cdot c = 2 \cdot 6 = 12$
        \item $3|7m \; \nexists c \; t.c. \; 3 \cdot c = 7 \; \forall c \in \mathbb{Z}$
    \end{itemize}
\end{boxA}

\textbf{Proprietà}:
\begin{itemize}[nosep]
    \item \textbf{transitività}: se $n|m$ e $m|q$ allora $n|q$.
    \begin{boxA}
        \textcolor{olive}{\textbf{Dimostrazione}} \\
        Hp. $\exists h \in \mathbb{Z} \; | \; m = h \cdot n \qquad \exists h' \in \mathbb{Z} \; | \; q = h' \cdot m$ \\
        Sostituendo la prima relazione nella seconda si ottiene $q = h' \cdot h \cdot n$. Poichè $h' \cdot h \in \mathbb{Z}$ abbiamo definito che $n|q$.
    \end{boxA}

    \item se $n|m$ e $m|n$, allora $m \pm n$.
    \begin{boxA}
        \textcolor{olive}{\textbf{Dimostrazione}} \\
        Hp. $\exists h \in \mathbb{Z} \; | \; m = h \cdot n \qquad \exists h' \in \mathbb{Z} \; | \; n = h' \cdot m$ \\
        Andiamo a sostituire la seconda alla prima equazione:
        \begin{align*}
            n &= h' \cdot h \cdot m \\
            n - h' \cdot h \cdot m &= 0 \\
            n \cdot (1 - h' \cdot h) &= 0
        \end{align*}
        Essendo che $\mathbb{Z}$ è un \textbf{dominio di integrità}, segue che o $n = 0$ oppure $(1 - h' \cdot h) = 0 \rightarrow (h' \cdot h) = 1$, consideriamo che $n \leq 0$ e che quindi $h' \cdot h = 1$ sappiamo che $h$ ammette un inverso $h'$, da cui $h = h' = 1$ o $h = h' = -1$ (in $\mathbb{Z}$, gli unici elementi che ammettono inverso sono $1$ e $-1$). In questo modo sappiamo che $m=n$ oppure $m=-n$.
    \end{boxA}
\end{itemize}

\section{Massimo Comune Divisore}
Dati $a,b \in \mathbb{Z}$ non entrambi nulli, si dice che $d \in \mathbb{Z}$ è \textcolor{red}{\textbf{UN}} \textbf{massimo comune divisore} tra $a$ e $b$ se valgono contemporaneamente le due proprietà:
\begin{center}
    $d|a \; \text{e} \; d|b \qquad \forall d' \in \mathbb{Z} \; | \; d'|a, \; d'|b \Rightarrow d'|d$
\end{center}

\begin{boxA}
    Se $d$ e $d'$ sono due massimi comuni divisori tra $a$ e $b$ allora $d' = \pm d$. \\ \newline
    \textcolor{olive}{\textbf{Dimostrazione}} \\
    $\forall d' \in \mathbb{Z} \; \Rightarrow \; d'|a, \; d|b \; \Rightarrow \; d'|d \; \Rightarrow \; d=\pm d'$ \\
    $\forall d \in \mathbb{Z} \; d|a, \; d|b \; \Rightarrow \; d|d'$
\end{boxA}
Dati $a, b \in \mathbb{Z}$ non entrambi nulli, si dice che $d \in \mathbb{Z}^+$ è \textcolor{red}{\textbf{IL}} \textbf{massimo comune divisore} (\textbf{\textit{Greatest Common Divisor}}) tra $a,b$ se $d$ è un \textit{massimo comune divisore} fra $a$ e $b$ (fra i due possibili \textbf{MCD} prendo il massimo, quindi quello positivo).

{\centering
    $d = \gcd(a, b)$
\par}

\begin{boxA}
    \textcolor{orange}{\textbf{Esempio}} \\
    Se $a|b$, allora $\gcd(a, b) = |a|$ e in particolare $\gcd(a, 0) = |a| \; \forall a \in \mathbb{Z} - \{0\}$
\end{boxA}

Dati $a, b \in \mathbb{Z}$ non entrambi nulla, allora \fcolorbox{red}{white}{$\exists ! \gcd(a, b)$} e viene inoltre definita l'\textbf{Identità di \textit{Bezout}} che rappresenta il massimo comun divisore come combinazione lineare di $a$ e $b$:

{\centering
    $\gcd(a, b) = a \cdot \alpha + b \cdot \beta$
\par}

Questi valori ($\alpha$ e $\beta$) però non sono strettamente univocamente determinata, infatti in generale una coppia di numeri interi hanno più di un $\alpha$ e un $\beta$ definiti.

\begin{boxA}
    \textcolor{olive}{\textbf{Dimostrazione}} \\
    Consideraiamo un insieme S costituito da tutte le combinazioni lineari intere di $a, b$ che abbia però risultati strettamente positivi.
    
    {\centering
        $S = \{\lambda \cdot a + \mu \cdot b \; \vert \; \lambda, \mu \in \mathbb{Z}, \; \lambda \cdot a + \mu \cdot b > 0\}$
    \par}

    Osserviamo che l'insieme S non è vuoto ($S \neq \emptyset$), infatti almeno uno tra $a$ e $b$ non è nullo, infatti ponendo $a \neq 0$ è possibile affermare che:

    {\centering
        $| a | = \text{(segno)} \cdot a + 0 \cdot b \; \rightarrow \; | a | \in S$
    \par}

    Osserviamo che S contiene unicamente numeri naturali possiamo dire che $S \subseteq \mathbb{N}$ non vuoto e che quindi $\exists \min(s) = d$ ovvero l'insieme è limitato inferiormente. Siccome $d \in S$ questo vuol dire che è rappresentabile come \textbf{combinazione lineare}, ovvero \fcolorbox{red}{white}{$\exists \overline{\lambda}, \overline{\mu} \in \mathbb{Z} \; t.c. \; d = \overline{\lambda} \cdot a + \overline{\mu} \cdot b$}. \\
    Adesso cerchiamo di dimostrare che questo $d$ è proprio il massimo comune divisore che stavo cercando: \fcolorbox{red}{white}{\textbf{Th.} $d = \gcd(a, b)$} ovvero che $d|a$ e che $d|b$.
    \begin{itemize}[nosep]
        \item partiamo \textcolor{olive}{dimostrando} che $a|b$, andiamo a considerare la \textbf{divisione euclidea} tra $a$ e $d$.

        {\centering
            $\exists q \in \mathbb{Z}, \; \exists r \in \mathbb{Z}, \; 0 \leq r < d \; \vert \; a = q \cdot d + r$
            \begin{align*}
            r &= a - q \cdot d \\
            &= a - q \cdot (\overline{\lambda} \cdot a + \overline{\mu} \cdot b) \\
            &= a - q \cdot \overline{\lambda} \cdot a + q \cdot \overline{\mu} \cdot b \\
            &= a \cdot \underset{\in \mathbb{Z}}{\fcolorbox{red}{white}{$(1 - q \cdot \overline{\lambda})$}} + b \cdot \underset{\in \mathbb{Z}}{\fcolorbox{red}{white}{$q \cdot \overline{\mu}$}}
            \end{align*}
        \par}

        In questo modo abbiamo scritto $r$ come combinazione lineare di due interi, ma \textbf{se} $r \neq 0$ allora $r \in S$ siccome, però, $r < d$ e $d = \min(S)$ arriviamo ad un \textcolor{red}{\textbf{assurdo}}, quindi affinché vengano rispettati i vincoli bisogna che $r = 0 \quad \Rightarrow \quad a = q \cdot d + 0 = q \cdot d$ e quindi \fcolorbox{red}{white}{$d|a$}

        \item in perfetta analogia si può dimostrare che \fcolorbox{red}{white}{$d|b$}, partendo dalla \textbf{divisione euclidea} tra $b$ e $d$.
    \end{itemize}
\end{boxA}

\begin{boxA}
    \begin{itemize}[nosep]
        \item bisogna ora \textcolor{olive}{dimostrare} che $\forall d' \in \mathbb{Z} \; | \; d'|a, \; d'|b \Rightarrow d'|d$. Poiché $d = \overline{\lambda} \cdot a + \overline{\mu} \cdot b$ allora bisognerà che \fcolorbox{red}{white}{$\exists h \in \mathbb{Z} \; | \; a = d' \cdot h$} e \fcolorbox{red}{white}{$\exists k \in \mathbb{Z} \; | \; b = d' \cdot k$}. Usando queste due relazioni, segue che:
        \begin{align*}
            d &= \overline{\lambda} \cdot d' \cdot h + \overline{\mu} \cdot d' \cdot k \\
            &= d' \cdot \underset{\in \mathbb{Z}}{\fcolorbox{red}{white}{$[(\overline{\lambda} \cdot h) + (\overline{\mu} \cdot k)]$}}
        \end{align*}

        In questo modo siamo riusciti a dimostrare che $d'|d$.
    \end{itemize}
    Siamo riusciti a dimostrare il teorema di esistenza del \textbf{massimo comune divisore} in S, come il suo minimo: $d = \min(S) = \gcd(a, b)$
\end{boxA}

Siano $a,b \in \mathbb{Z}$, con $|a| \geq |b| > 0$. Se $a = b \cdot q + r$ è la \textbf{divisione euclidea} fra $a$ e $b$ allora avremo:
\begin{center}
    $\{c \in \mathbb{Z} \; \vert \; c | a, \; c | b \} = \{c \in \mathbb{Z} \; | \; c | b, \; c | r \}$
\end{center}
Ovvero l'insieme degli interi che dividono $a$ e $b$ sono gli stessi che dividono sia $b$ che $r$, conseguenza di questo fatto è che:
\begin{center}
     $\gcd(a, b) = \gcd(b, r)$
\end{center}

\begin{boxA}
    \textcolor{olive}{\textbf{Dimostrazione}}
    \begin{itemize}[nosep]
        \item partiamo dal primo insieme: $\{c \in \mathbb{Z} \; \vert \; c | a, \; c | b \}$ andiamo a dimostrare che \fcolorbox{red}{white}{\textbf{Th.} $c|r$} (perché che $c|b$ è implicito per la costruzione del problema). Poiché $c|a$ e $c|b$ allora:
        
        {\centering
            $\exists h \in \mathbb{Z} \; \text{t.c.} \; a = c \cdot h \qquad \exists k \in \mathbb{Z} \; \text{t.c.} \; b = c \cdot k$
        \par}

        Consideriamo ora la \textbf{divisione euclidea} tra $a$ e $b$ avremo che:
        \begin{align*}
            r &= a - b \cdot q \\
            &= c \cdot h - c \cdot k \cdot q \\
            & = \underset{\in \mathbb{Z}}{\underline{c \cdot (h - k \cdot q)}}
        \end{align*}
        Quindi in questo modo abbiamo dimostrato che $c|r$.
    \end{itemize}
\end{boxA}

\begin{boxA}
    \begin{itemize}[nosep]
        \item affrontiamo ora il secondo insieme $\{c \in \mathbb{Z} \; | \; c | b, \; c | r \}$ e andiamo a dimostrare che \fcolorbox{red}{white}{\textbf{Th.} $c|a$} (perché che $c|b$ è implicito per la costruzione del problema). Poichè $c|b$ e $c|r$ allora:

        {\centering
            $\exists h \in \mathbb{Z} \; \text{t.c.} \; b = c \cdot h \qquad \exists k \in \mathbb{Z} \; \text{t.c.} \; r = c \cdot k$
        \par}

        Consideriamo la \textbf{divisione euclidea} tra $a$ e $b$ avremo che:
        \begin{align*}
            a &= b \cdot q + r \\
            &= c \cdot h \cdot q + c \cdot k \\
            &= c \cdot \underset{\in \mathbb{Z}}{\underline{(h \cdot q + k)}}
        \end{align*} 
        Quindi in questo modo abbiamo dimostrato che $c|a$.
    \end{itemize}
\end{boxA}

\textbf{Algoritmo delle Divisioni Successive (di Euclide)}