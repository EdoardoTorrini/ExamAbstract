\chapter{Gli Interi e la Divisibilità}
\section{Strutture algebriche elementari}
Una \textbf{operazione binaria intera} su un insieme G è un'applicazione 
\begin{center}
    $\ast \; : \; G \times G \rightarrow G$
\end{center}
L'immagine della coppia $(x,y)$ si denoterà con $x \ast y$. 
\begin{itemize}[nosep]
    \item $e \in G$ si dice \textbf{elemento neutro} rispetto a $\ast$ se:
    \begin{center}
        $g \ast e = e \ast g = g \; \forall g \in G$
    \end{center}
    \item un elemento $g \in G$ si dice invertibile se esiste $\bar{g} \in G$ tale che $g * \bar{g} = \bar{g} * g = e$
\end{itemize}

\subsection{Gruppi}
La coppia $(G, \ast)$, con $\ast$ operazione su G, si dice \textbf{gruppo} se vengono rispettate le seguenti proprietà:
\begin{itemize}[nosep]
    \item $\ast$ è \textbf{associativa}: $\forall g, g', g'' \in G$ si ha $(g \ast g') \ast g'' = g \ast (g' \ast g'')$
    \item esiste l'elemento \textbf{neutro}
    \item ogni elemento di G è invertibile
\end{itemize}
Il gruppo si dice \textbf{abeliano} o \textbf{commutativo} se: 
\begin{center}
    $\forall g, g' \in G, \; g \ast g' = g' \ast g$ (proprietà \textbf{commutativa})
\end{center}
Alcuni \textcolor{orange}{\textbf{esempi}}:
\begin{itemize}[nosep]
    \item $(\mathbb{N}, +)$, $(\mathbb{Z}, \cdot)$ non sono gruppi. In quanto non né in $\mathbb{N}$ né in $\mathbb{Z}$ è presente per ogni elemento dell'insieme l'elemento inverso, in $\mathbb{N}$ non sono presenti elementi negativi, quindi nessun elemento avrà un'altro elemento che sommato a se stesso dia 0, viceversa l'insieme $\mathbb{Z}$ dove sono presenti elementi positivi e negativi viene, invece, definita l'operazione $\cdot$ che richiede i reciproci dei singoli elementi affiché possano essere definiti gli elementi inversi.
    \item $(\mathbb{Z}, +)$, $(\mathbb{Q}, \cdot)$ sono gruppi abelliani
\end{itemize}

\subsection{Anelli}
La terna $(\mathbb{A}, +, \cdot)$ con $\mathbb{A}$ un insieme e $+, \cdot$ (somma e prodotto) due operazione binarie interne a $\mathbb{A}$, si dice \textbf{anello} se:
\begin{itemize}[nosep]
    \item $(\mathbb{A}, +, \cdot)$ è un gruppo \textbf{abeliano} (con elemento neutro 0).
    \item il prodotto è \textbf{associativo}.
    \item per ogni $x,y,z \in \mathbb{K}$ si ha $x \cdot (y + z) = (x \cdot y) + (x \cdot z)$ e $(x + y) \cdot z = (x \cdot z) + (y \cdot z)$ (il prodotto è distribuito rispetto alla somma).
\end{itemize}
Un anello $(\mathbb{A}, +, \cdot)$ è detto \textbf{commutativa} se il prodotto è commutativo, mentre è detto \textbf{unitario} o con \textbf{unità} se $(\mathbb{A}, \cdot)$ ammette l'elemento neutro. $(\mathbb{Z}, +, \cdot)$, $(\mathbb{Q}, +, \cdot)$, $(\mathbb{R}, +, \cdot)$, $(\mathbb{C}, +, \cdot)$ sono anelli.

\subsection{Campi}
La terna $(\mathbb{K}, +, \cdot)$ con $\mathbb{K}$ un insieme e $+, \cdot$ (somma e prodotto) due operazioni binarie interne a $\mathbb{K}$, si dice \textbf{campo} se:
\begin{itemize}[nosep]
    \item $(\mathbb{K}, +)$ è un gruppo \textbf{abeliano} (con elemento neutro 0).
    \item $(\mathbb{K} - \{0\}, \cdot)$ è un gruppo \textbf{abeliano} (con elemento neutro 1).
    \item per ogni $x,y,z \in \mathbb{K}$ si ha $x \cdot (y + z) = (x \cdot y) + (x \cdot z)$ quindi il prodotto è distribuito rispetto alla somma.
\end{itemize}
In qualunque campo vale la \textbf{legge di annullamento del prodotto}:
\begin{center}
    $x \cdot y = 0 \rightarrow x = 0 \; \text{oppure} \; y = 0$
\end{center}

\subsection{Domini d'integrità}
\textbf{Divisori dello zero}: sia $(A, +, \cdot)$ un anello. Due elementi $a,b \in A$ si dicono \textbf{divisori dello zero} se $a \neq 0$, $b \neq 0$, ma $a \cdot b = 0$. Ovvero, può succedere che in un anello due elementi non nulli il cui prodotto fa 0.
\begin{boxA}
    Ad \textcolor{orange}{\textbf{esempio}} l'anello delle matrici quadrate presenta dei divisori dello zero, infatti due matrici non nulle è possibile che il loro prodotto presenti la matrice nulla.
    \begin{center}
        \begin{math}
            A = \begin{pmatrix}
                1 & 1 \\
                1 & 1
                \end{pmatrix}, \quad B = \begin{pmatrix}
                1 & -1 \\
                -1 & 1
                \end{pmatrix}
        \end{math}
        \begin{math}
            A \cdot B = \begin{pmatrix}
                1 & 1 \\
                1 & 1
                \end{pmatrix} \cdot \begin{pmatrix}
                1 & -1 \\
                -1 & 1
                \end{pmatrix} = \begin{pmatrix}
                (1 \cdot 1 + 1 \cdot -1) & (1 \cdot -1 + 1 \cdot 1) \\
                (1 \cdot 1 + 1 \cdot -1) & (1 \cdot -1 + 1 \cdot 1)
                \end{pmatrix} = \begin{pmatrix}
                0 & 0 \\
                0 & 0
                \end{pmatrix}
        \end{math}
    \end{center}    
\end{boxA}
\textbf{Dominio di Integrità}: Un anello commutativo privo di divisori dello zero si dice \textbf{dominio di integrità}.

\begin{boxA}
    Ad \textcolor{orange}{\textbf{esempio}} $(\mathbb{Z}, +, \cdot)$ è un \textbf{anello commutativo unitario} privo di divisori dello zero. Quindi è dominio di integrità.
\end{boxA}

\section{L'anello dei numeri interi}
È noto che $\exists h \; | \; h : \mathbb{Z} \rightarrow \frac{\mathbb{N}_0 \times \mathbb{N}_0}{\mathcal{R}}$ dove la relazione di equivalenza che si vuole definire è $\equiv_n$. Su questo insieme vengono \textbf{ben poste} le seguenti operazioni:
\begin{center}
    $\boxplus : \mathbb{Z} \times \mathbb{Z} \rightarrow \mathbb{Z}$ \\
    $((m, n), (m', n')) \mapsto [(m, n)] \boxplus [(m', n')] \myeq [(m + m', n + n')]$

    $\boxdot : \mathbb{Z} \times \mathbb{Z} \rightarrow \mathbb{Z}$ \\
    $((m, n), (m', n')) \mapsto [(m, n)] \boxdot [(m', n')] \myeq [(mm' + nn', mn' + m'n)]$
\end{center}
Definito questo possiamo dire che $(\mathbb{Z}, \boxplus, \boxdot)$ è \textbf{dominio di integrità}.

\section{Teoria della Divisibilità}
\textbf{Divisibilità}: dati due numeri $a,b \in \mathbb{Z}$, si dice che $a$ \textbf{divide} $b$ (e si scrive $a|b$) se: $\exists c \in \mathbb{Z} \; | \; b = a \cdot c$
\begin{boxA}
    \textcolor{orange}{\textbf{Esempi}}
    \begin{itemize}[nosep]
        \item $2|12, \; \exists c \; t.c. \; 2 \cdot c = 2 \cdot 6 = 12$
        \item $3|7m \; \nexists c \; t.c. \; 3 \cdot c = 7 \; \forall c \in \mathbb{Z}$
    \end{itemize}
\end{boxA}

\textbf{Proprietà}:
\begin{itemize}[nosep]
    \item \textbf{transitività}: se $n|m$ e $m|q$ allora $n|q$.
    \begin{boxA}
        \textcolor{olive}{\textbf{Dimostrazione}} \\
        Hp. $\exists h \in \mathbb{Z} \; | \; m = h \cdot n \qquad \exists h' \in \mathbb{Z} \; | \; q = h' \cdot m$ \\
        Sostituendo la prima relazione nella seconda si ottiene $q = h' \cdot h \cdot n$. Poichè $h' \cdot h \in \mathbb{Z}$ abbiamo definito che $n|q$.
    \end{boxA}

    \item se $n|m$ e $m|n$, allora $m \pm n$.
    \begin{boxA}
        \textcolor{olive}{\textbf{Dimostrazione}} \\
        Hp. $\exists h \in \mathbb{Z} \; | \; m = h \cdot n \qquad \exists h' \in \mathbb{Z} \; | \; n = h' \cdot m$ \\
        Andiamo a sostituire la seconda alla prima equazione:
        \begin{align*}
            n &= h' \cdot h \cdot m \\
            n - h' \cdot h \cdot m &= 0 \\
            n \cdot (1 - h' \cdot h) &= 0
        \end{align*}
        Essendo che $\mathbb{Z}$ è un \textbf{dominio di integrità}, segue che o $n = 0$ oppure $(1 - h' \cdot h) = 0 \rightarrow (h' \cdot h) = 1$, consideriamo che $n \leq 0$ e che quindi $h' \cdot h = 1$ sappiamo che $h$ ammette un inverso $h'$, da cui $h = h' = 1$ o $h = h' = -1$ (in $\mathbb{Z}$, gli unici elementi che ammettono inverso sono $1$ e $-1$). In questo modo sappiamo che $m=n$ oppure $m=-n$.
    \end{boxA}
\end{itemize}

\section{Massimo Comune Divisore}
Dati $a,b \in \mathbb{Z}$ non entrambi nulli, si dice che $d \in \mathbb{Z}$ è \textcolor{red}{\textbf{UN}} \textbf{massimo comune divisore} tra $a$ e $b$ se valgono contemporaneamente le due proprietà:
\begin{center}
    $d|a \; \text{e} \; d|b \qquad \forall d' \in \mathbb{Z} \; | \; d'|a, \; d'|b \Rightarrow d'|d$
\end{center}

\begin{boxA}
    Se $d$ e $d'$ sono due massimi comuni divisori tra $a$ e $b$ allora $d' = \pm d$. \\ \newline
    \textcolor{olive}{\textbf{Dimostrazione}} \\
    $\forall d' \in \mathbb{Z} \; \Rightarrow \; d'|a, \; d|b \; \Rightarrow \; d'|d \; \Rightarrow \; d=\pm d'$ \\
    $\forall d \in \mathbb{Z} \; d|a, \; d|b \; \Rightarrow \; d|d'$
\end{boxA}
Dati $a, b \in \mathbb{Z}$ non entrambi nulli, si dice che $d \in \mathbb{Z}^+$ è \textcolor{red}{\textbf{IL}} \textbf{massimo comune divisore} (\textbf{\textit{Greatest Common Divisor}}) tra $a,b$ se $d$ è un \textit{massimo comune divisore} fra $a$ e $b$ (fra i due possibili \textbf{MCD} prendo il massimo, quindi quello positivo).

{\centering
    $d = \gcd(a, b)$
\par}

\begin{boxA}
    \textcolor{orange}{\textbf{Esempio}} \\
    Se $a|b$, allora $\gcd(a, b) = |a|$ e in particolare $\gcd(a, 0) = |a| \; \forall a \in \mathbb{Z} - \{0\}$
\end{boxA}

Dati $a, b \in \mathbb{Z}$ non entrambi nulla, allora \fcolorbox{red}{white}{$\exists ! \gcd(a, b)$} e viene inoltre definita l'\textbf{Identità di \textit{Bezout}} che rappresenta il massimo comun divisore come combinazione lineare di $a$ e $b$:

{\centering
    $\gcd(a, b) = a \cdot \alpha + b \cdot \beta$
\par}

Questi valori ($\alpha$ e $\beta$) però non sono strettamente univocamente determinata, infatti in generale una coppia di numeri interi hanno più di un $\alpha$ e un $\beta$ definiti.

\begin{boxA}
    \textcolor{olive}{\textbf{Dimostrazione}} \\
    Consideraiamo un insieme S costituito da tutte le combinazioni lineari intere di $a, b$ che abbia però risultati strettamente positivi.
    
    {\centering
        $S = \{\lambda \cdot a + \mu \cdot b \; \vert \; \lambda, \mu \in \mathbb{Z}, \; \lambda \cdot a + \mu \cdot b > 0\}$
    \par}

    Osserviamo che l'insieme S non è vuoto ($S \neq \emptyset$), infatti almeno uno tra $a$ e $b$ non è nullo, infatti ponendo $a \neq 0$ è possibile affermare che:

    {\centering
        $| a | = \text{(segno)} \cdot a + 0 \cdot b \; \rightarrow \; | a | \in S$
    \par}

    Osserviamo che S contiene unicamente numeri naturali possiamo dire che $S \subseteq \mathbb{N}$ non vuoto e che quindi $\exists \min(s) = d$ ovvero l'insieme è limitato inferiormente. Siccome $d \in S$ questo vuol dire che è rappresentabile come \textbf{combinazione lineare}, ovvero \fcolorbox{red}{white}{$\exists \overline{\lambda}, \overline{\mu} \in \mathbb{Z} \; t.c. \; d = \overline{\lambda} \cdot a + \overline{\mu} \cdot b$}. \\
    Adesso cerchiamo di dimostrare che questo $d$ è proprio il massimo comune divisore che stavo cercando: \fcolorbox{red}{white}{\textbf{Th.} $d = \gcd(a, b)$} ovvero che $d|a$ e che $d|b$.
    \begin{itemize}[nosep]
        \item partiamo \textcolor{olive}{dimostrando} che $a|b$, andiamo a considerare la \textbf{divisione euclidea} tra $a$ e $d$.

        {\centering
            $\exists q \in \mathbb{Z}, \; \exists r \in \mathbb{Z}, \; 0 \leq r < d \; \vert \; a = q \cdot d + r$
            \begin{align*}
            r &= a - q \cdot d \\
            &= a - q \cdot (\overline{\lambda} \cdot a + \overline{\mu} \cdot b) \\
            &= a - q \cdot \overline{\lambda} \cdot a + q \cdot \overline{\mu} \cdot b \\
            &= a \cdot \underset{\in \mathbb{Z}}{\fcolorbox{red}{white}{$(1 - q \cdot \overline{\lambda})$}} + b \cdot \underset{\in \mathbb{Z}}{\fcolorbox{red}{white}{$q \cdot \overline{\mu}$}}
            \end{align*}
        \par}

        In questo modo abbiamo scritto $r$ come combinazione lineare di due interi, ma \textbf{se} $r \neq 0$ allora $r \in S$ siccome, però, $r < d$ e $d = \min(S)$ arriviamo ad un \textcolor{red}{\textbf{assurdo}}, quindi affinché vengano rispettati i vincoli bisogna che $r = 0 \quad \Rightarrow \quad a = q \cdot d + 0 = q \cdot d$ e quindi \fcolorbox{red}{white}{$d|a$}

        \item in perfetta analogia si può dimostrare che \fcolorbox{red}{white}{$d|b$}, partendo dalla \textbf{divisione euclidea} tra $b$ e $d$.
    \end{itemize}
\end{boxA}

\begin{boxA}
    \begin{itemize}[nosep]
        \item bisogna ora \textcolor{olive}{dimostrare} che $\forall d' \in \mathbb{Z} \; | \; d'|a, \; d'|b \Rightarrow d'|d$. Poiché $d = \overline{\lambda} \cdot a + \overline{\mu} \cdot b$ allora bisognerà che \fcolorbox{red}{white}{$\exists h \in \mathbb{Z} \; | \; a = d' \cdot h$} e \fcolorbox{red}{white}{$\exists k \in \mathbb{Z} \; | \; b = d' \cdot k$}. Usando queste due relazioni, segue che:
        \begin{align*}
            d &= \overline{\lambda} \cdot d' \cdot h + \overline{\mu} \cdot d' \cdot k \\
            &= d' \cdot \underset{\in \mathbb{Z}}{\fcolorbox{red}{white}{$[(\overline{\lambda} \cdot h) + (\overline{\mu} \cdot k)]$}}
        \end{align*}

        In questo modo siamo riusciti a dimostrare che $d'|d$.
    \end{itemize}
    Siamo riusciti a dimostrare il teorema di esistenza del \textbf{massimo comune divisore} in S, come il suo minimo: $d = \min(S) = \gcd(a, b)$
\end{boxA}

Siano $a,b \in \mathbb{Z}$, con $|a| \geq |b| > 0$. Se $a = b \cdot q + r$ è la \textbf{divisione euclidea} fra $a$ e $b$ allora avremo:
\begin{center}
    $\{c \in \mathbb{Z} \; \vert \; c | a, \; c | b \} = \{c \in \mathbb{Z} \; | \; c | b, \; c | r \}$
\end{center}
Ovvero l'insieme degli interi che dividono $a$ e $b$ sono gli stessi che dividono sia $b$ che $r$, conseguenza di questo fatto è che:
\begin{center}
     $\gcd(a, b) = \gcd(b, r)$
\end{center}

\begin{boxA}
    \textcolor{olive}{\textbf{Dimostrazione}}
    \begin{itemize}[nosep]
        \item partiamo dal primo insieme: $\{c \in \mathbb{Z} \; \vert \; c | a, \; c | b \}$ andiamo a dimostrare che \fcolorbox{red}{white}{\textbf{Th.} $c|r$} (perché che $c|b$ è implicito per la costruzione del problema). Poiché $c|a$ e $c|b$ allora:
        
        {\centering
            $\exists h \in \mathbb{Z} \; \text{t.c.} \; a = c \cdot h \qquad \exists k \in \mathbb{Z} \; \text{t.c.} \; b = c \cdot k$
        \par}

        Consideriamo ora la \textbf{divisione euclidea} tra $a$ e $b$ avremo che:
        \begin{align*}
            r &= a - b \cdot q \\
            &= c \cdot h - c \cdot k \cdot q \\
            & = c \cdot \underset{\in \mathbb{Z}}{\underline{(h - k \cdot q)}}
        \end{align*}
        Quindi in questo modo abbiamo dimostrato che $c|r$.
    \end{itemize}
\end{boxA}

\begin{boxA}
    \begin{itemize}[nosep]
        \item affrontiamo ora il secondo insieme $\{c \in \mathbb{Z} \; | \; c | b, \; c | r \}$ e andiamo a dimostrare che \fcolorbox{red}{white}{\textbf{Th.} $c|a$} (perché che $c|b$ è implicito per la costruzione del problema). Poichè $c|b$ e $c|r$ allora:

        {\centering
            $\exists h \in \mathbb{Z} \; \text{t.c.} \; b = c \cdot h \qquad \exists k \in \mathbb{Z} \; \text{t.c.} \; r = c \cdot k$
        \par}

        Consideriamo la \textbf{divisione euclidea} tra $a$ e $b$ avremo che:
        \begin{align*}
            a &= b \cdot q + r \\
            &= c \cdot h \cdot q + c \cdot k \\
            &= c \cdot \underset{\in \mathbb{Z}}{\underline{(h \cdot q + k)}}
        \end{align*} 
        Quindi in questo modo abbiamo dimostrato che $c|a$.
    \end{itemize}
\end{boxA}

\textbf{Algoritmo delle Divisioni Successive (di Euclide)} \\
Siano $a, b \in \mathbb{Z} - \{0\}$. Applicando ricorsivamente la divisione euclidea tra $a$ e $|b|$, e poi tra \textbf{divisore} e \textbf{resto} della divisione:

\begin{figure}[h]
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \begin{align*}
            a &= |b| \cdot q_1 + r_1 \\
            b &= r_1 \cdot q_2 + r_2 \\
            r_1 &= r_2 \cdot q_3 + r_3 \\
            & ... \\
            r_{n - 1} &= r_n \cdot q_{n + 1} + 0
        \end{align*}
    \end{minipage}
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \begin{align*}
            & \gcd (a, b) \\
            & \gcd (b, r_1) \\
            & \gcd (r_1, r_2) \\
            & .. \\
            & \gcd (r_{n - 1}, r_n) = r_n
        \end{align*}
    \end{minipage}
\end{figure}
Poiché $r_1 > r_2 > r_3 > ... > r_i > ... \geq 0$, $\exists n \in \mathbb{N} \; \text{t.c.} \; r_{n + 1} = 0$ allora: $\gcd (a, b) = r_n$

\begin{boxA}
    \textcolor{orange}{\textbf{Esempio}}: $\gcd (3522, 321) = \; ?$

    {\centering
        \[
            \renewcommand{\arraystretch}{0.7}
            \begin{array}{rcl}
                3522 & = & (10) \cdot 321 + \fcolorbox{brown}{white}{312} \\
                321  & = & (1) \cdot 312 + \fcolorbox{blue}{white}{9} \\
                312  & = & (34) \cdot 9 + \fcolorbox{olive}{white}{6} \\
                9    & = & (1) \cdot 6 + \fcolorbox{red}{white}{3} \\
                6    & = & (2) \cdot 3 + 0
            \end{array}
        \]
    \par}
    Quindi: $\gcd (3522, 321) = 3$
\end{boxA}
È possibile utilizzando l'\textbf{Algoritmo delle Divisioni Successive} è possibile ricavare anche i parametri $\alpha$ e $\beta$ dell'\textbf{Identità di Bezout} di $a$ e $b$ andando a ritroso e rappresentando il resto in funzione del valore di partenza e del dividendo.
\begin{boxA}
    \textcolor{orange}{\textbf{Esempio}}:    
    \begin{align*}
        \gcd (3522, 321) &= 3 \\
        &= \fcolorbox{red}{white}{$9 - (1) \cdot 6$} \\
        &= 9 - (1) \cdot \fcolorbox{olive}{white}{$[312 - (34) \cdot 9]$} \\
        &= 9 - 312 + (34) \cdot 9 \\
        &= -312 + (35) \cdot 9 \\
        &= -312 + (35) \cdot \fcolorbox{blue}{white}{$[321 - (1) \cdot 312]$} \\
        &= -312 + (35) \cdot 321 - (35) \cdot 312 \\
        &= (35) \cdot 321 - (36) \cdot 312 \\
        &= (35) \cdot 321 - (36) \cdot \fcolorbox{brown}{white}{$[3522 - (10) \cdot 321]$} \\ 
        &= (35) \cdot 321 - (36) \cdot 3522 + (360) \cdot 321 \\
        &= \underset{= \alpha}{\fcolorbox{red}{white}{$(-36)$}} \cdot 3522 + \underset{= \beta}{\fcolorbox{red}{white}{$(395)$}} \cdot 321
    \end{align*}
    Avremo quindi: $\gcd (3522, 321) = 3 = \alpha \cdot 3522 + \beta \cdot 321 = (-36) \cdot 3522 + (395) \cdot 321$
\end{boxA}
\textbf{Complessità computazionale}: l'Algoritmo delle Divisioni Successive di Euclide per il calcolo del $\gcd (a, b)$ termina al più in \fcolorbox{red}{white}{$2\log_2 |b|$} passi.
\begin{boxA}
    \textcolor{olive}{\textbf{Dimostrazione}} \\
    Si verifica che, ogni due divisioni successive, il resto (almeno) si dimezza: 
    
    {\centering
        $r_{2k} < \frac{r_{2k - 2}}{2}$
    \par}
    Allora, se $k$ è tale che $\frac{|b|}{2^k} < 1$, si ha $r_{2k} = 0 \quad \forall k \in \mathbb{N}$. D'altra parte, $|b| < 2^k$ il che significa che $k > \log_2 |b|$. Siccome ad ogni variazione di $k$ corrispondono due passi dell'algoritmo, allora questo terminerà in un numero intero di passi minore o uguale a $2\log_2 |b|$
\end{boxA}

\newpage
\section{Equazioni Diofantee}
Una \textbf{equazione diofantea} è un'equazione lineare di primo rado in due incognite a coefficienti interi, di cui si ricercano le soluzioni intere:

{\centering
    $a \cdot x + b \cdot y = c, \qquad \text{con } a, b, c \in \mathbb{Z}$
\par}

\begin{flushleft}
    Le soluzioni (\textbf{se esistono}) sono coppie del tipo:

    {\centering
        $(\overline{x}, \overline{y}) \in \mathbb{Z} \times \mathbb{Z} \; \text{t.c.} \; a \cdot \overline{x} + b \cdot \overline{y} = c$
    \par}
\end{flushleft}
\begin{flushleft}
    L'equazione diofantea $ax + by = c, \; \text{con } a, b, c \in \mathbb{Z}$ \textbf{ammette soluzioni} (intere) se e solo se $\gcd (a, b)| c$. Inoltre se $(\overline{x}, \overline{y})$ è una soluzione, allora esistono infinite soluzioni:

    {\centering
        Sol = $\{(\overline{x}, \overline{y}) + k \cdot \frac{(-b, a)}{\gcd (a, b)} \; \text{t.c.} \; k \in \mathbb{Z}\}$
    \par}
\end{flushleft}

\begin{boxA}
    \textcolor{olive}{\textbf{Dimostrazione}}: quando bisogna dimostrare un \textbf{se e solo se} ($\longleftrightarrow$), la dimostrazine sarà divisia in due parti: la prima parte dimostrerà il ``$\rightarrow$'', mentre la seconda il ``$\leftarrow$'' \\ \newline
    \textcolor{red}{\textbf{Prima Parte}} \\
    \textbf{Hp}: $\exists (\overline{x}, \overline{y}) \in \mathbb{Z} \times \mathbb{Z} \; \text{t.c.} \; a\overline{x} + b\overline{y} = c$ \\
    \textbf{Th}: $\underset{d \in \mathbb{Z}}{\underbrace{\gcd (a, b)}|c}$
    
    \begin{center}
        \centering
        \begin{minipage}[t]{0.4\textwidth}
            Per definizione avremo che $d|a$ e che $d|b$
        \end{minipage}
        $\Rightarrow$
        \begin{minipage}[t]{0.4\textwidth}
            \centering
            $\exists h \in \mathbb{Z} \; \text{t.c.} \; a = d \cdot h$ \\
            $\exists k \in \mathbb{Z} \; \text{t.c.} \; b = d \cdot k$
        \end{minipage}
    \end{center}
    Allora:
    \begin{center}
        \centering
        \begin{minipage}[t]{0.4\textwidth}
            \centering
            $d \cdot h \cdot \overline{x} + d \cdot k \cdot \overline{y} = c$ \\
            $d \cdot \underset{\in \mathbb{Z}}{\fcolorbox{red}{white}{$(h \cdot \overline{x} + k \cdot \overline{y})$}} = c$
        \end{minipage}
        \begin{minipage}[t]{0.5\textwidth}
            \centering
            $d|c$ in questo modo abbiamo dimostrato che $\gcd (a, b)$ divide il termine noto $c$
        \end{minipage}
    \end{center}
\end{boxA}

\begin{boxA}
    \textcolor{red}{\textbf{Seconda Parte}} \\
    \textbf{Hp}: $\gcd (a, b)|c$ \\
    \textbf{Th}: $\exists (\overline{x}, \overline{y}) \in \mathbb{Z} \times \mathbb{Z} \; \text{t.c.} \; a\overline{x} + b\overline{y} = c$ \\
    Poniamo $d \in \mathbb{Z}, \; d = \gcd (a, b)$ è possibile scriverlo attraverso l'\textbf{identità di bezout} come:
    
    {\centering
        $\exists \alpha, \beta \in \mathbb{Z} \; \text{t.c.} \; d = \alpha \cdot a + \beta \cdot b$
    \par}
    Poiché $d|c$ allora $\exists h \in \mathbb{Z} \; \text{t.c.} \; c = d \cdot h$ andando a sostituire avremo che:
    \begin{align*}
        c = d \cdot h &= (\alpha \cdot a + \beta \cdot b) \cdot h \\
        &= a \cdot \underset{\in \mathbb{Z}}{\underbrace{(\alpha \cdot h)}} + b \cdot \underset{\in \mathbb{Z}}{\underbrace{(\beta \cdot h)}}
    \end{align*}
    In questo modo abbiamo dimostrato che $(\overline{x}, \overline{y}) = (a \cdot h, b \cdot h)$ e che quindi \textbf{se esiste} è soluzione. \\ \newline
    \textcolor{red}{\textbf{Terza Parte}} \\
    L'ultima parte della dimostrazione ci permette di verificare che \textbf{se esiste} una soluzione, ne \textbf{esistono infinite}, ovvero se:

    {\centering
        $\exists (\overline{x}, \overline{y}) \in \mathbb{Z} \times \mathbb{Z} \rightarrow \exists \infty \; \text{soluzioni}$
    \par}
    Facciamo riferimento a un sistema lineare completo come insieme delle soluzioni, quello che si ottiene è una soluzione ``particolare'' alla verrà aggiunto l'insieme di tutte le soluzioni del \textbf{sistema omogeneo associato}: $\mathcal{S}$ è un sistema e $\mathcal{S}_0$ è il sistema omogeneo associato (ovvero sostituiso il vettore colonna dei termini noti con degli $0$) allora la mia soluzione sarà:
    
    {\centering
        $Sol(\mathcal{S}) = \{\overline{x} + Sol(\mathcal{S}_0)\}$
    \par}
    \begin{center}
        \begin{minipage}[t]{0.45\textwidth}
            \centering
            Nel nostro caso avremo come $\mathcal{S}: \; a \cdot x + b \cdot y = c$ e quindi avremo che \fcolorbox{red}{white}{$(\overline{x}, \overline{y}) \in Sol(\mathcal{S})$}
        \end{minipage}
        \begin{minipage}[t]{0.45\textwidth}
            \centering
            Mentre $\mathcal{S}_0: \; a \cdot x + b \cdot y = 0$ è quindi immediato che $(-b, a) \in Sol(\mathcal{S}_0)$, ma quindi faranno parte di $Sol(\mathcal{S}_0)$ tutti i loro multipli e sottomultipli.
        \end{minipage} \\
        \fcolorbox{red}{white}{$Sol(\mathcal{S}_0) = k \cdot \frac{(-b, a)}{\gcd (a, b)}$}
    \end{center}

    Quindi avremo che $Sol(\mathcal{S}) = \{(\overline{x}, \overline{y}) + k \cdot \frac{(-b, a)}{\gcd (a, b)} \; \text{t.c.} \; k \in \mathbb{Z}\}$
\end{boxA}

\section{Numeri Primi e Coprimi}
